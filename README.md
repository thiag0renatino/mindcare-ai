<h1 align="center">
  <br>
  MindCare AI ‚Äî Backend
  <br>
</h1>

<p align="center">
  API RESTful para triagem inteligente, monitoramento de bem-estar e gest√£o corporativa de sa√∫de utilizando IA generativa.
</p>

<p align="center">
  <img alt="Java" src="https://img.shields.io/badge/Java-17-ED8B00?style=for-the-badge&logo=openjdk&logoColor=white" />
  <img alt="Spring Boot" src="https://img.shields.io/badge/Spring_Boot-3-6DB33F?style=for-the-badge&logo=springboot&logoColor=white" />
  <img alt="Spring AI" src="https://img.shields.io/badge/Spring_AI-Azure_OpenAI-6DB33F?style=for-the-badge&logo=spring&logoColor=white" />
</p>

---

## Ecossistema MindCare

Este reposit√≥rio cont√©m o **backend (API)** do MindCare AI. O sistema √© composto por dois reposit√≥rios:

| Componente | Reposit√≥rio | Tecnologia |
|---|---|---|
| API ‚Äî este reposit√≥rio | [mindcare-ai](https://github.com/thiag0renatino/mindcare-ai) | Spring Boot |
| Interface Web | [mindcare-ai-ui](https://github.com/thiag0renatino/mindcare-ai-ui) | Angular |

> A interface web consome diretamente esta API. Para executar o sistema completo, inicialize o backend primeiro e em seguida a UI, apontando para `http://localhost:8080`.

---

## Descri√ß√£o do Projeto

O **MindCare AI** √© uma solu√ß√£o desenvolvida para melhorar o acompanhamento da sa√∫de f√≠sica e mental dos trabalhadores dentro do ambiente corporativo.
A aus√™ncia de um sistema automatizado de triagem, hist√≥rico de sa√∫de e integra√ß√£o entre empresas, colaboradores e profissionais compromete:

- a **agilidade** na detec√ß√£o de riscos;
- a **precis√£o** na classifica√ß√£o de casos;
- o **encaminhamento eficiente** para profissionais ou a√ß√µes;
- a **vis√£o unificada** do bem-estar organizacional.

Este projeto prop√µe uma solu√ß√£o robusta que possibilita:

- **Triagem inteligente**, interpretando relatos de colaboradores e classificando risco como baixo, moderado ou alto;
- **Armazenamento completo do hist√≥rico** de triagens, encaminhamentos e acompanhamentos;
- **API RESTful** moderna com Java Spring Boot, seguindo boas pr√°ticas (DTOs, servi√ßos, valida√ß√µes, exce√ß√µes globais etc.);
- **Integra√ß√£o ativa com IA**, respons√°vel por interpretar relatos e sugerir a√ß√µes com encaminhamentos por especialidade;
- **Estrutura organizada** de entidades relacionadas (Empresa, Usu√°rio, Triagem, Encaminhamento, Acompanhamento).

üìå **P√∫blico-alvo:** Departamentos de RH, profissionais de sa√∫de e equipes respons√°veis pelo bem-estar corporativo.

---

## Como a MindCheck AI est√° funcionando

O fluxo de triagem inteligente utiliza o Spring AI com Azure OpenAI (configuradas via vari√°veis `AZURE_OPENAI_*`) e funciona da seguinte forma:

1. **Endpoint protegido** `POST /api/mindcheck-ai/analises` recebe o relato e dados opcionais sobre sintomas, humor e rotina. O usu√°rio √© identificado automaticamente via token JWT.
2. **Rate limiting via Redis**: cada usu√°rio pode realizar no m√°ximo **10 an√°lises por hora**. Excedido o limite, a API retorna erro at√© a janela ser renovada.
3. **Prompting estruturado**: o `MindCheckAiService` monta uma instru√ß√£o fixa para o modelo gerar um JSON contendo risco, sugestoes, encaminhamentos e justificativa. Qualquer JSON inv√°lido dispara uma `MindCheckAiException`.
4. **Persist√™ncia autom√°tica**: a resposta √© convertida em `MindCheckAiResponseDTO`, uma nova `Triagem` √© salva e, quando o risco √© `MODERADO` ou `ALTO`, **um `Encaminhamento` √© criado automaticamente para cada especialidade sugerida pela IA**, com prioridade proporcional ao risco.
5. **Retorno completo**: o payload da IA j√° vem acrescido dos dados da triagem persistida e da lista de encaminhamentos gerados.

Esse fluxo garante que toda an√°lise realizada pela IA deixe registros no banco (triagem e encaminhamentos).

---

### Credenciais obrigat√≥rias para IA

Para executar o endpoint `/api/mindcheck-ai/analises` √© necess√°rio configurar, no arquivo `.env`, as credenciais da Azure OpenAI utilizadas pelo Spring AI:

```env
AZURE_OPENAI_API_KEY=<sua-chave>
AZURE_OPENAI_ENDPOINT=https://<resource>.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=<deployment-gpt4o-ou-outro>
```

Sem esses valores, o `ChatClient` n√£o consegue gerar o diagn√≥stico automatizado.

**Como provisionar no Azure**
1. No portal Azure, crie um recurso "Foundry" (Azure AI Foundry / AI Studio), escolhendo uma regi√£o dispon√≠vel e um Resource Group.
2. Dentro do recurso, acesse `Keys & Endpoint` para copiar o `Endpoint` (`AZURE_OPENAI_ENDPOINT`) e gerar a chave (`AZURE_OPENAI_API_KEY`).
3. Na aba `Deployments`, crie um novo deployment para o modelo desejado (ex.: GPT-4o) e use o nome definido como o valor da vari√°vel `AZURE_OPENAI_DEPLOYMENT`.
4. Para mais detalhes, consulte a documenta√ß√£o oficial: [Criar recurso](https://learn.microsoft.com/azure/ai-services/openai/how-to/create-resource).

### Vari√°veis de ambiente

| Vari√°vel | Descri√ß√£o | Obrigat√≥rio |
|---|---|---|
| `DB_USERNAME` / `DB_PASSWORD` | Credenciais do banco MySQL | Sim |
| `JWT_SECRET` | Chave para assinar tokens JWT | Sim |
| `AZURE_OPENAI_API_KEY` | Chave de acesso √† Azure OpenAI | Sim |
| `AZURE_OPENAI_ENDPOINT` | Endpoint do recurso Azure OpenAI | Sim |
| `AZURE_OPENAI_DEPLOYMENT` | Nome do deployment do modelo (ex.: gpt-4o) | Sim |
| `REDIS_HOST` / `REDIS_PORT` | Host e porta do Redis (default: `localhost`/`6379`) | N√£o |
| `RABBITMQ_HOST` / `RABBITMQ_PORT` | Host e porta do RabbitMQ (default: `localhost`/`5672`) | N√£o |
| `RABBITMQ_USERNAME` / `RABBITMQ_PASSWORD` | Credenciais do broker (default: `guest`/`guest`) | N√£o |
| `MINDCHECK_EXCHANGE` / `MINDCHECK_QUEUE` / `MINDCHECK_ROUTING_KEY` | Identificadores das filas utilizadas | N√£o |

> Azure OpenAI e Redis s√£o obrigat√≥rios. RabbitMQ e demais vari√°veis j√° possuem defaults e s√≥ precisam ser configurados se o ambiente diferir do padr√£o local.

### Infraestrutura local (Docker)

Para desenvolvimento local, os servi√ßos de infraestrutura podem ser iniciados com Docker:

```bash
# Redis (obrigat√≥rio)
docker run -d --name mindcheck-redis -p 6379:6379 redis:7

# RabbitMQ (opcional ‚Äî apenas se quiser testar a mensageria)
docker run -d --name mindcheck-rabbit -p 5672:5672 -p 15672:15672 rabbitmq:3-management
```

### Mensageria ass√≠ncrona

- Cada triagem da MindCheck AI publica um `TriagemAvaliacaoEvent` no RabbitMQ (`mindcheck.triagem.exchange`).
- O listener `MindCheckAiEventListener` consome os eventos para processar alertas/dashboards sem bloquear a requisi√ß√£o.
- Caso n√£o queira iniciar o RabbitMQ localmente, defina `mindcheck.rabbitmq.enabled=false` no `application.properties` (j√° √© o valor padr√£o) para desabilitar todos os beans de mensageria.

#### Como testar a mensageria
1. Inicie o RabbitMQ com o comando acima (usu√°rio `guest/guest`).
2. Defina `mindcheck.rabbitmq.enabled=true` no `application.properties`.
3. Rode a API (`mvn spring-boot:run`) e acesse `http://localhost:15672` para confirmar a fila `mindcheck.triagem.queue`.
4. Autentique-se e chame `POST /api/mindcheck-ai/analises` com payload v√°lido.
5. No painel do RabbitMQ, verifique que a fila recebeu a mensagem e logo ficou vazia (listener consumiu).
6. Veja os logs da aplica√ß√£o: `MindCheckAiEventListener` deve registrar o risco e as especialidades recomendadas.

---

## Tecnologias e Ferramentas Utilizadas

- **Java 17**
- **Spring Boot 3**
- **Spring AI + Azure OpenAI (GPT-4o)** ‚Äì an√°lise autom√°tica de relatos com temperatura calibrada (`0.2`)
- **Spring Security + JWT** ‚Äì autentica√ß√£o e autoriza√ß√£o
- **Spring Data JPA** com **MySQL**
- **Redis** ‚Äì rate limiting por usu√°rio e cache de idempot√™ncia das an√°lises
- **Spring AMQP (RabbitMQ)** ‚Äì mensageria ass√≠ncrona
- **MapStruct** ‚Äì mapeamento DTO ‚Üî entidade
- **Springdoc OpenAPI / Swagger UI** ‚Äì documenta√ß√£o interativa
- **Maven**

### M√≥dulos Spring Utilizados

- `Spring Web` ‚Äì constru√ß√£o da API RESTful
- `Spring Data JPA` ‚Äì persist√™ncia de dados
- `Spring Data Redis` ‚Äì integra√ß√£o com Redis para cache e rate limiting
- `Spring Validation` ‚Äì valida√ß√£o das requisi√ß√µes
- `Spring Security` ‚Äì autentica√ß√£o e autoriza√ß√£o com JWT
- `Spring HATEOAS` ‚Äì enriquecimento hipertextual das respostas
- `Springdoc OpenAPI` ‚Äì documenta√ß√£o autom√°tica da API

### Persist√™ncia de Dados

- **MySQL** ‚Äì banco de dados relacional utilizado no projeto

---

## Documenta√ß√£o e Testes da API

- **Swagger / OpenAPI** ‚Äì documenta√ß√£o interativa
- **Swagger UI** ‚Äì testes manuais diretamente no browser
- **Postman** ‚Äì testes externos

A documenta√ß√£o estar√° dispon√≠vel em:

üëâ `http://localhost:8080/swagger-ui/index.html`

---

## Pr√©-requisitos

- Java 17+
- Maven 3.8+
- MySQL
- Redis
- Criar arquivo `.env` na raiz do projeto contendo:

```env
# Banco de dados
DB_USERNAME=
DB_PASSWORD=

# Seguran√ßa
JWT_SECRET=

# Azure OpenAI (obrigat√≥rio para o endpoint de IA)
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_DEPLOYMENT=

# Redis (opcional ‚Äî padr√£o: localhost:6379)
REDIS_HOST=
REDIS_PORT=

# RabbitMQ (opcional ‚Äî padr√£o: localhost:5672 / guest:guest)
RABBITMQ_HOST=
RABBITMQ_PORT=
RABBITMQ_USERNAME=
RABBITMQ_PASSWORD=
MINDCHECK_EXCHANGE=
MINDCHECK_QUEUE=
MINDCHECK_ROUTING_KEY=
```

---

## ‚ñ∂Ô∏è Como Executar

```bash
# Clone o reposit√≥rio
git clone https://github.com/thiag0renatino/mindcare-ai.git
cd mindcare-ai

# Compile o projeto
mvn clean install

# Execute a aplica√ß√£o
mvn spring-boot:run
```

API dispon√≠vel em:
üëâ `http://localhost:8080`

---

## Endpoints principais

- **Auth**
  - `POST /auth/register` ‚Üí Registra novo usu√°rio
  - `POST /auth/login` ‚Üí Autentica usu√°rio e gera token JWT
  - `PUT /auth/refresh-token` ‚Üí Gera novo token a partir do refresh token
  - `POST /auth/logout` ‚Üí Invalida o token atual via Redis
- **MindCheck AI**
  - `POST /api/mindcheck-ai/analises` ‚Üí Requer Bearer token; executa o fluxo de IA, persiste a triagem, cria um encaminhamento por especialidade sugerida e retorna o resultado completo.
- Demais recursos (Triagem, Encaminhamento, Acompanhamento, Empresa etc.) est√£o detalhados no Swagger e tamb√©m exigem autentica√ß√£o JWT.

---

## Licen√ßa

Projeto ‚Äì FIAP Global Solution 2025.
